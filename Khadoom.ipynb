{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**خدوم**"
      ],
      "metadata": {
        "id": "VJAWEJdW2rVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1fCBBn1oauIu",
        "outputId": "32d9b102-a901-4f33-d06b-f6246e943733"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.24.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.3 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from huggingface_hub import InferenceClient\n",
        "import PyPDF2\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import base64\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://huggingface.co/api/inference-proxy/together\",\n",
        "    api_key=\"\"  # Replace with your own key\n",
        ")\n",
        "# ---------------- UI -----------------------------------------\n",
        "st.set_page_config(page_title=\"Qwen Chatbot\", layout=\"centered\")\n",
        "\n",
        "st.title(\"ServeItUp\")\n",
        "st.image(\"/content/IMG_9054 (1).PNG\", width=100)  # Adjust width as needed\n",
        "\n",
        "st.write(\"Chat with AI customer Service\")\n",
        "st.write(\"Upload a PDF (FAQs, company policies)\")\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF document\", type=\"pdf\")\n",
        "\n",
        "if \"document_text\" not in st.session_state:\n",
        "    st.session_state.document_text = \"\"\n",
        "\n",
        "if uploaded_file:\n",
        "    pdf_reader = PyPDF2.PdfReader(uploaded_file)\n",
        "    extracted_text = \"\\n\".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])\n",
        "    st.session_state.document_text = extracted_text\n",
        "    st.success(\"✅ PDF uploaded and processed!\")\n",
        "\n",
        "# ------------------ System Prompt for Chatbot ------------------\n",
        "SYSTEM_PROMPT = \"\"\"You are an AI customer support assistant.\n",
        "You MUST answer concisely based ONLY on the provided document.\n",
        "\n",
        "### Rules:\n",
        "- **Only answer from the document**.\n",
        "- **DO NOT speculate or make up answers**.\n",
        "- **If the answer is unknown, respond:** \"I don't have that information in the document.\"\n",
        "- **DO NOT repeat or rephrase the user’s question**.\n",
        "- **DO NOT start responses with 'User:' or repeat conversation history**.\n",
        "- **DO NOT include \"<think>\" statements or reasoning processes**.\n",
        "- **DO NOT ignore polite feedback like 'That was helpful' or 'Thank you'—instead, respond with 'You're welcome.'**\n",
        "- **Give direct answers in a professional tone**.\n",
        "\n",
        "### Examples:\n",
        "**User:** Who wrote 'Hamlet'?\n",
        "**Assistant:** William Shakespeare.\n",
        "\n",
        "**User:** That was helpful.\n",
        "**Assistant:** You're welcome.\n",
        "\n",
        "**User**: This is not what I asked for.\n",
        "**Assistant**: I’m sorry, let me clarify.\n",
        "\n",
        "**User**: You're not answering my question correctly.\n",
        "**Assistant**: I apologize for any confusion, I am under development, your question will be handled by a human.\n",
        "\n",
        "**User:** What is the CEO’s name?\n",
        "**Assistant:** I don’t have that information in the document.\n",
        "\"\"\"\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
        "    ]\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    if message[\"role\"] == \"system\":\n",
        "        continue\n",
        "    role = \"🤖\" if message[\"role\"] == \"assistant\" else \"👤\"\n",
        "    st.chat_message(role).write(message[\"content\"])\n",
        "\n",
        "# ------------------ User Chat Input ------------------\n",
        "user_input = st.chat_input(\"Type your message...\")\n",
        "\n",
        "if user_input and st.session_state.document_text:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"deepseek-ai/DeepSeek-R1\",\n",
        "        messages=st.session_state.messages,\n",
        "        max_tokens=256\n",
        "    )\n",
        "\n",
        "    bot_reply = completion.choices[0].message.content.strip()\n",
        "    bot_reply = re.sub(r\"<think>.*?</think>\", \"\", bot_reply, flags=re.DOTALL).strip()\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "\n",
        "    st.chat_message(\"👤\").write(user_input)\n",
        "    st.chat_message(\"🤖\").write(bot_reply)\n",
        "\n",
        "elif user_input:\n",
        "    st.warning(\"⚠️ Please upload a PDF first!\")\n",
        "\n",
        "# ------------------ Sentiment Analysis Prompt ------------------\n",
        "SENTIMENT_PROMPT = \"\"\"Analyze the conversation and determine the customer's satisfaction level.\n",
        "\n",
        "### **Rules:**\n",
        "- **A normal Q&A conversation where the AI provides an answer → \"The customer is satisfied.\"**\n",
        "- **If the user complains, expresses frustration, or says the assistant is wrong or 'I am not happy' → \"The customer is not satisfied.\"**\n",
        "- **If the user expresses gratitude (e.g., \"Thanks,\" \"That was helpful\") → \"The customer is satisfied.\"**\n",
        "- **ONLY return one of these two responses:**\n",
        "  - \"The customer is satisfied.\"\n",
        "  - \"The customer is not satisfied.\"\n",
        "- **DO NOT explain your reasoning.**\n",
        "- **DO NOT add any extra text or \"<think>\" statements.**\n",
        "- **DO NOT assume dissatisfaction unless the user explicitly expresses frustration.**\n",
        "\n",
        "### **Examples:**\n",
        "**Example 1 (Satisfied)**\n",
        "User: Who wrote 'Hamlet'?\n",
        "Assistant: William Shakespeare.\n",
        "User: That was helpful.\n",
        "Assistant: You're welcome.\n",
        "Output → \"The customer is satisfied.\"\n",
        "\n",
        "**Example 2 (Not Satisfied)**\n",
        "User: You're not answering my question correctly.\n",
        "Assistant: I apologize for any confusion, I am under development, your question will be handled by a human.\n",
        "Output → \"The customer is not satisfied.\"\n",
        "\n",
        "**Example 3 (User says \"I am not happy\" - Not Satisfied)**\n",
        "User: This is not what I asked for, I am not happy with your answer.\n",
        "Assistant: I’m sorry, let me clarify.\n",
        "Output → \"The customer is not satisfied.\"\n",
        "\n",
        "**Example 4 (Satisfied, Neutral but Helpful)**\n",
        "User: Thank you, that was helpful!\n",
        "Assistant: You're welcome!\n",
        "Output → \"The customer is satisfied.\"\n",
        "\n",
        "**Example 5 (Frustrated User, Not Satisfied)**\n",
        "User: This is not what I asked for.\n",
        "Assistant: I’m sorry, let me clarify.\n",
        "Output → \"The customer is not satisfied.\"\n",
        "\n",
        "**Example 6 (Short Conversation, But Answered Correctly)**\n",
        "User: What is the capital of France?\n",
        "Assistant: Paris.\n",
        "Output → \"The customer is satisfied.\"\n",
        "\n",
        "Now analyze the following conversation and determine the final result:\n",
        "\"\"\"\n",
        "\n",
        "# ------------------ \"End Conversation\" for Sentiment ------------------\n",
        "if st.button(\"End Conversation\"):\n",
        "    if len(st.session_state.messages) > 1:\n",
        "        formatted_conversation = \"\\n\".join([\n",
        "            f\"{msg['role'].capitalize()}: {msg['content']}\"\n",
        "            for msg in st.session_state.messages if msg[\"role\"] != \"system\"\n",
        "        ])\n",
        "\n",
        "        sentiment_response = client.chat.completions.create(\n",
        "            model=\"deepseek-ai/DeepSeek-R1\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant. Your task is to analyze customer satisfaction based on conversation history.\"},\n",
        "                {\"role\": \"user\", \"content\": SENTIMENT_PROMPT + formatted_conversation}\n",
        "            ],\n",
        "            max_tokens=50\n",
        "        )\n",
        "\n",
        "        sentiment_result = sentiment_response.choices[0].message.content.strip()\n",
        "        sentiment_result = re.sub(r\"<think>.*?</think>\", \"\", sentiment_result, flags=re.DOTALL).strip()  # Ensure <think> is removed\n",
        "\n",
        "\n",
        "        conversation_lower = formatted_conversation.lower()\n",
        "        NEGATIVE_KEYWORDS = [\n",
        "            \"this is not what i asked for\",\n",
        "            \"i am not happy\",\n",
        "            \"not answering my question correctly\",\n",
        "            \"upset\",\n",
        "            \"angry\",\n",
        "            \"frustrated\"\n",
        "        ]\n",
        "        if any(keyword in conversation_lower for keyword in NEGATIVE_KEYWORDS):\n",
        "            final_sentiment = \"The customer is not satisfied.\"\n",
        "        else:\n",
        "            if \"not satisfied\" in sentiment_result:\n",
        "                final_sentiment = \"The customer is not satisfied.\"\n",
        "            else:\n",
        "                final_sentiment = \"The customer is satisfied.\"\n",
        "\n",
        "        st.subheader(\"Conversation Sentiment Analysis:\")\n",
        "        st.success(final_sentiment)\n",
        "\n",
        "        st.session_state.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "    else:\n",
        "        st.warning(\"⚠️ No conversation available for sentiment analysis!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw0G21VkkWyT",
        "outputId": "3b81612b-a8d5-47a4-912b-5f511b476dfe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7ofGgCBfSpi",
        "outputId": "7d20c57d-c898-4477-fb28-0b80db354218"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ngrok.tunnel_ext:error connecting to upstream error=Cannot assign requested address (os error 99)\n",
            "WARNING:ngrok.tunnel_ext:error connecting to upstream error=Cannot assign requested address (os error 99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3xCNBz_dMCB",
        "outputId": "abc22577-bc58-48ed-c229-88392e8fba46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ngrok\n",
            "  Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/3.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ngrok\n",
            "Successfully installed ngrok-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ngrok\n",
        "secret = \"2rrXTthXeGOp6AHKIwlIHdIRyUj_7Qss4a5AkTeBJViSsajJH\"\n",
        "# asynchronous execution: do this but do not wait for it until it is done, complete and go run the next line\n",
        "listner = await ngrok.forward(8501, authtoken =secret)\n",
        "print(listner.url())\n",
        "\n",
        "!streamlit run app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3qqfgPTebcb3",
        "outputId": "c156440e-e24b-4726-f306-891dfd2c6b33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://a27e-34-125-7-90.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.7.90:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}