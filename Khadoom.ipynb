{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**خدوم**"
      ],
      "metadata": {
        "id": "VJAWEJdW2rVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1fCBBn1oauIu",
        "outputId": "9fb1e6f8-f52f-48e9-e996-7336a64e2149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.24.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.3 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from huggingface_hub import InferenceClient\n",
        "import PyPDF2\n",
        "from openai import OpenAI\n",
        "import re\n",
        "# ------------------ Page UI ------------------\n",
        "st.set_page_config(page_title=\"Khadoom \", page_icon=\"🤖\", layout=\"wide\")\n",
        "page = st.sidebar.selectbox(\"Navigation\", [\"📄 Upload PDF\", \"💬 Chatbot\"])\n",
        "# --------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# ------------------ Hugging Face API Connection ------------------\n",
        "client = OpenAI(\n",
        "    base_url=\"https://huggingface.co/api/inference-proxy/together\",\n",
        "    api_key=\"hf_xxx\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# ------------------ PDF Upload Page ------------------\n",
        "if page == \"📄 Upload PDF\":\n",
        "    st.title(\"Khadoom\")\n",
        "    st.image(\"/content/khadoom logo.PNG\", width=100)\n",
        "    st.title(\"📄 Upload a PDF (FAQs, Policies, etc.)\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Upload a PDF document\", type=\"pdf\")\n",
        "\n",
        "    if \"document_text\" not in st.session_state:\n",
        "        st.session_state.document_text = \"\"\n",
        "\n",
        "    if uploaded_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(uploaded_file)\n",
        "        extracted_text = \"\\n\".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])\n",
        "        st.session_state.document_text = extracted_text  # Store extracted text globally\n",
        "        st.success(\"✅ PDF uploaded and processed!\")\n",
        "\n",
        "        st.info(\" khadoom is ready to  answer to customers 🤖\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ------------------ Chatbot Page ------------------\n",
        "elif page == \"💬 Chatbot\":\n",
        "    st.title(\"💬 Khadoom Chatbot 🤖\")\n",
        "    st.image(\"/content/khadoom logo.PNG\", width=100)\n",
        "\n",
        "    # Ensure PDF is uploaded before chat\n",
        "    if \"document_text\" not in st.session_state or not st.session_state.document_text:\n",
        "        st.warning(\"⚠️ Please upload a PDF first on the 'Upload PDF' page!\")\n",
        "        st.stop()  # Prevents further execution\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------ System Prompt  ------------------\n",
        "SYSTEM_PROMPT = \"\"\"You are an AI customer support assistant named \"Khadoom\".\n",
        "You MUST answer concisely based ONLY on the provided document.\n",
        "The question of the user might not be direct, so you need to understand the user request to be able to fetch the correct answer from the pdf\n",
        "\n",
        "### Rules:\n",
        "- **Only answer from the document**.\n",
        "- **DO NOT speculate or make up answers**.\n",
        "- **If the answer is unknown, respond:** \"I don't have that information in the document.\"\n",
        "- **DO NOT repeat or rephrase the user’s question**.\n",
        "- **DO NOT start responses with 'User:' or repeat conversation history**.\n",
        "- **DO NOT include \"<think>\" statements or reasoning processes**.\n",
        "- **DO NOT ignore polite feedback like 'That was helpful' or 'Thank you'—instead, respond with 'You're welcome.'**\n",
        "- **Give direct answers in a professional tone**.\n",
        "- ** You should greet the user back and say goodbye back or see you soon!\"\n",
        "\n",
        "### Examples:\n",
        "**User:** Who wrote 'Hamlet'?\n",
        "**Assistant:** William Shakespeare.\n",
        "\n",
        "**User:** That was helpful.\n",
        "**Assistant:** You're welcome.\n",
        "\n",
        "**User**: This is not what I asked for.\n",
        "**Assistant**: I’m sorry, let me clarify.\n",
        "\n",
        "**User**: You're not answering my question correctly.\n",
        "**Assistant**: I apologize for any confusion, I am under development, your question will be handled by a human.\n",
        "\n",
        "**User:** What is the CEO’s name?\n",
        "**Assistant:** I don’t have that information in the document.\n",
        "\n",
        "**User:** hi\n",
        "**Assistant:** hello, what can I help with?\n",
        "\n",
        "\n",
        "**User:** what is your name?\n",
        "**Assistant:** my name I Khadoom!\n",
        "\n",
        "**User:** at which point does the water get frozen?\n",
        "**Assistant:** :  Water freezes at 0 degrees Celsius or 32 degrees Fahrenheit.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# ----------------------Chat History----------------------------\n",
        "if \"messages\" not in st.session_state:\n",
        "  st.session_state.messages = [\n",
        "      {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
        "  ]\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "  if message[\"role\"] == \"system\":\n",
        "      continue\n",
        "  role = \"🤖\" if message[\"role\"] == \"assistant\" else \"👤\"\n",
        "  st.chat_message(role).write(message[\"content\"])\n",
        "\n",
        "user_input = st.chat_input(\"Type your message...\")\n",
        "\n",
        "if user_input and st.session_state.document_text:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"deepseek-ai/DeepSeek-R1\",\n",
        "        messages=st.session_state.messages,\n",
        "        max_tokens=256\n",
        "    )\n",
        "\n",
        "    bot_reply = completion.choices[0].message.content.strip()\n",
        "    bot_reply = re.sub(r\"<think>.*?</think>\", \"\", bot_reply, flags=re.DOTALL).strip()\n",
        "    bot_reply = bot_reply.replace(\"<think>\", \"\").replace(\"</think>\", \"\").strip()  # Additional safeguard\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "\n",
        "    st.chat_message(\"👤\").write(user_input)\n",
        "    st.chat_message(\"🤖\").write(bot_reply)\n",
        "\n",
        "elif user_input:\n",
        "    st.warning(\"⚠️ Please upload a PDF first!\")\n",
        "\n",
        "\n",
        "# ------------------ Sentiment Analysis Prompt ------------------\n",
        "SENTIMENT_PROMPT = \"\"\"Analyze the conversation and determine the customer's satisfaction level.\n",
        "\n",
        "### **Rules:**\n",
        "- **A normal Q&A conversation where the AI provides an answer → \"The customer is satisfied.\"**\n",
        "- **If the user complains, expresses frustration, or says the assistant is wrong or 'I am not happy' → \"The customer is not satisfied.\"**\n",
        "- **If the user expresses gratitude (e.g., \"Thanks,\" \"That was helpful\") → \"The customer is satisfied.\"**\n",
        "- **ONLY return one of these two responses:**\n",
        "  - \"The customer is satisfied.\"\n",
        "  - \"The customer is not satisfied.\"\n",
        "- **DO NOT explain your reasoning.**\n",
        "- **DO NOT add any extra text or \"<think>\" statements.**\n",
        "- **DO NOT assume dissatisfaction unless the user explicitly expresses frustration.**\n",
        "\n",
        "### **Examples:**\n",
        "**Example 1 (Satisfied)**\n",
        "User: Who wrote 'Hamlet'?\n",
        "Assistant: William Shakespeare.\n",
        "User: That was helpful.\n",
        "Assistant: You're welcome.\n",
        "Output → \"The customer is satisfied.\"\n",
        "\n",
        "**Example 2 (Not Satisfied)**\n",
        "User: You're not answering my question correctly.\n",
        "Assistant: I apologize for any confusion, I am under development, your question will be handled by a human.\n",
        "Output → \"The customer is not satisfied.\"\n",
        "\n",
        "**Example 3 (User says \"I am not happy\" - Not Satisfied)**\n",
        "User: This is not what I asked for, I am not happy with your answer.\n",
        "Assistant: I’m sorry, let me clarify.\n",
        "Output → \"The customer is not satisfied.\"\n",
        "\n",
        "**Example 4 (Satisfied, Neutral but Helpful)**\n",
        "User: Thank you, that was helpful!\n",
        "Assistant: You're welcome!\n",
        "Output → \"The customer is satisfied.\"\n",
        "\n",
        "**Example 5 (Frustrated User, Not Satisfied)**\n",
        "User: This is not what I asked for.\n",
        "Assistant: I’m sorry, let me clarify.\n",
        "Output → \"The customer is not satisfied.\"\n",
        "\n",
        "**Example 6 (Short Conversation, But Answered Correctly)**\n",
        "User: What is the capital of France?\n",
        "Assistant: Paris.\n",
        "Output → \"The customer is satisfied.\"\n",
        "\n",
        "Now analyze the following conversation and determine the final result:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# ------------------ End Conversation Button ------------------\n",
        "if st.button(\"End Conversation\"):\n",
        "  if len(st.session_state.messages) > 1:\n",
        "      formatted_conversation = \"\\n\".join([\n",
        "          f\"{msg['role'].capitalize()}: {msg['content']}\"\n",
        "          for msg in st.session_state.messages if msg[\"role\"] != \"system\"\n",
        "      ])\n",
        "\n",
        "      sentiment_response = client.chat.completions.create(\n",
        "          model=\"deepseek-ai/DeepSeek-R1\",\n",
        "          messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a sentiment analysis assistant. Your task is to analyze customer satisfaction based on conversation history.\"+  SENTIMENT_PROMPT },\n",
        "                {\"role\": \"user\", \"content\": formatted_conversation}\n",
        "            ],\n",
        "          max_tokens=50\n",
        "      )\n",
        "\n",
        "      sentiment_result = sentiment_response.choices[0].message.content.strip()\n",
        "      sentiment_result = re.sub(r\"<think>.*?</think>\", \"\", sentiment_result, flags=re.DOTALL).strip()\n",
        "      sentiment_result = sentiment_result.replace(\"<think>\", \"\").replace(\"</think>\", \"\").strip()  # Additional safeguard\n",
        "\n",
        "\n",
        "      conversation_lower = formatted_conversation.lower()\n",
        "      NEGATIVE_KEYWORDS = [\n",
        "          \"this is not what i asked for\",\n",
        "          \"i am not happy\",\n",
        "          \"not answering my question correctly\",\n",
        "          \"upset\",\n",
        "          \"angry\",\n",
        "          \"frustrated\"\n",
        "      ]\n",
        "      if any(keyword in conversation_lower for keyword in NEGATIVE_KEYWORDS):\n",
        "          final_sentiment = \"The customer is not satisfied.\"\n",
        "      else:\n",
        "          if \"not satisfied\" in sentiment_result:\n",
        "              final_sentiment = \"The customer is not satisfied.\"\n",
        "          else:\n",
        "              final_sentiment = \"The customer is satisfied.\"\n",
        "\n",
        "      st.subheader(\"Conversation Sentiment Analysis:\")\n",
        "      st.success(final_sentiment)\n",
        "\n",
        "      st.session_state.messages = []\n",
        "  else:\n",
        "      st.warning(\"⚠️ No conversation available for sentiment analysis!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Oa1cQ1Z5LB",
        "outputId": "76df4623-56d7-4d57-a85b-301c77d90eef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7ofGgCBfSpi",
        "outputId": "e651f084-a6fb-45ca-d199-01b98ea51e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3xCNBz_dMCB",
        "outputId": "5434f59e-3715-4218-a728-ccb64f2f68e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ngrok\n",
            "  Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m171.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ngrok\n",
            "Successfully installed ngrok-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ngrok\n",
        "secret = \"xxx\"\n",
        "listner = await ngrok.forward(8501, authtoken =secret)\n",
        "print(listner.url())\n",
        "\n",
        "!streamlit run app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3qqfgPTebcb3",
        "outputId": "c027ff11-5dd7-47e5-9c7f-8a3dbff66b76"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://c25e-35-240-177-29.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.240.177.29:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}